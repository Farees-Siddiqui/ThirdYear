{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcd77e0e-9d4b-40fe-bf3b-b5eecb8e4e95",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Assignment 3 - Part I\n",
    "\n",
    "In this part, we are to perform preprocessing on text data.\n",
    "\n",
    "This involves you to:\n",
    "\n",
    "1. Complete the implementation of `helper.py`.\n",
    "2. Use the unit tests below to verify the functional correctness of your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5a7fb83-821c-448d-8128-2f11e3dee796",
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "\"ðŸ”’\"\n",
    "import torch\n",
    "import pandas as pd\n",
    "import helper\n",
    "from importlib import reload\n",
    "import sys, os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f458188-7e52-4f92-9500-05f6614727a2",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Load the dataset into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34e345f1-4b14-47c9-818c-4409a3fd4eac",
   "metadata": {
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bromwell high is a cartoon comedy . it ran at ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>story of a man who has unnatural feelings for ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>homelessness  or houselessness as george carli...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>airport    starts as a brand new luxury    pla...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brilliant over  acting by lesley ann warren . ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review     label\n",
       "0  bromwell high is a cartoon comedy . it ran at ...  positive\n",
       "1  story of a man who has unnatural feelings for ...  negative\n",
       "2  homelessness  or houselessness as george carli...  positive\n",
       "3  airport    starts as a brand new luxury    pla...  negative\n",
       "4  brilliant over  acting by lesley ann warren . ...  positive"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"ðŸ”’\"\n",
    "import gzip\n",
    "with gzip.open(f\"./IMDB_Review/labels.txt.gz\", 'r') as f:\n",
    "    lines = [x.decode('utf8').strip() for x in f.readlines()]\n",
    "    labels = pd.Series(lines)\n",
    "    \n",
    "with gzip.open(f'./IMDB_Review/reviews.txt.gz', 'r') as f:\n",
    "    lines = [x.decode('utf8').strip() for x in f.readlines()]\n",
    "    reviews = pd.Series(lines)\n",
    "    \n",
    "data_df = pd.DataFrame({\"review\": reviews, \"label\": labels})\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8aab3f6-66fe-4049-838a-d9f639924dff",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Tokenzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc1f153f-1d65-4274-824e-93e2b03c0ee4",
   "metadata": {
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['csci', '4050u', 'is', 'an', 'introduction', 'to', 'machine', 'learning', '.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"ðŸ”’\"\n",
    "# @check\n",
    "# @title: check tokenizer\n",
    "\n",
    "reload(helper)\n",
    "helper.tokenize(\"CSCI 4050U is an introduction to machine learning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2992e4a-230c-4d57-89b4-634fe532581a",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Iterate over reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba8074b4-697b-4fce-8eb4-c575af9d25f7",
   "metadata": {
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bromwell', 'high', 'is', 'a', 'cartoon', 'comedy', '.', 'it', 'ran', 'at']\n",
      "['story', 'of', 'a', 'man', 'who', 'has', 'unnatural', 'feelings', 'for', 'a']\n"
     ]
    }
   ],
   "source": [
    "\"ðŸ”’\"\n",
    "# @check\n",
    "# @title: check token iterator\n",
    "\n",
    "reload(helper)\n",
    "iterator = helper.iter_review_tokens(data_df)\n",
    "print(next(iterator)[:10])\n",
    "print(next(iterator)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409038de-b352-4d29-986b-cc63d878cc7e",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Build a vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1f89e5f-c0f4-49c0-ad84-694e2c8006cb",
   "metadata": {
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vocab()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"ðŸ”’\"\n",
    "# @check\n",
    "# @title: load the vocabulary\n",
    "\n",
    "reload(helper)\n",
    "vocab = helper.get_vocabulary(data_df, max_tokens=2000)\n",
    "vocab.set_default_index(vocab['<unk>'])\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d88339ff-b4b0-4f03-8b90-27f51b31228d",
   "metadata": {
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"ðŸ”’\"\n",
    "# @check\n",
    "# @title: check vocabulary length\n",
    "\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4339746-9347-48fc-92f7-a2963cf9f07f",
   "metadata": {
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>', '<unk>', '<start>', 'the', '.', 'and', 'a', 'of', 'to', 'is']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"ðŸ”’\"\n",
    "# @check\n",
    "# @title: verify the first ten tokens in the vocabulary\n",
    "\n",
    "vocab.lookup_tokens(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "016cb114-9554-47ef-be1a-88fb7710b161",
   "metadata": {
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 179, 53, 21, 1]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"ðŸ”’\"\n",
    "# @check\n",
    "# @title: verify the encodings by the vocabulary\n",
    "\n",
    "vocab.lookup_indices(['hello', 'world', 'good', 'movie', 'blah'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334f9ec9-a362-4944-b414-17b0e1b43c4b",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8fc96010-bfc1-46c6-9426-ec4aa0af4e12",
   "metadata": {
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataset.TensorDataset"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"ðŸ”’\"\n",
    "# convert data frame to a PyTorch dataset\n",
    "\n",
    "reload(helper)\n",
    "dataset = helper.get_review_dataset(data_df, vocab, max_length=200)\n",
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd20e3e1-e2e8-4a65-a2ba-137e1122c8a2",
   "metadata": {
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([   1,  311,    9,    6, 1053,  210,    4,   11,    1,   35,    3,  174,\n",
       "           60,   18,   52,   84,    1,   47,  385,  113,  143,   18,    1,    4,\n",
       "           63,  157,   12,    3,    1,    1,  478,   74,    8,  263,   15,    1,\n",
       "          311,   16, 1985,    9,   77,    1,    8,  616,   76,    9,    1,    4,\n",
       "            3,    1,    8, 1994,    1,    3,    1, 1507,   39,   54,   69,  207,\n",
       "          148,   70, 1205,    1,    1,    3,    1,    7,    3,  224,  886,   34,\n",
       "            1,   74,    7,    3,    1,   13,  690,    5,   70, 1507,    4,   57,\n",
       "           13,  219,    3,  386,   12,   65,    6, 1411,    1,  787,    8,    1,\n",
       "          183,    3,  385,   13, 1215,    1,    4,    4,    4,    4,    4,    4,\n",
       "            4,    4,    4,   35,    4,    4,    4,    4,    4,    4,    4,    4,\n",
       "            4,    4,  311,    4,    6,  352,  344,    1,   13,  146,  130,    8,\n",
       "            1,   33,    7,  132,    1,    4, 1411,    1,    8,    1,  311,    4,\n",
       "           13,  531,   15,  112, 1451,    7,   63,  546,  105,   15,    1,  311,\n",
       "            9,  230,    1,    4,   51,    6,    1,   15,   11,  218,   26,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " tensor(1))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"ðŸ”’\"\n",
    "# @check\n",
    "# @title: check dataset\n",
    "\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e22d962-93b4-448a-95ed-1e5e8c591a87",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Save dataset to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fdb0e285-cff5-4acb-b7eb-73424cbcc6a0",
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "\"ðŸ”’\"\n",
    "#\n",
    "# saving the data file\n",
    "#\n",
    "torch.save(dataset, './dataset.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a67f724a-33fe-4741-8a0f-eb16c434d4b5",
   "metadata": {
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size = 38 MB\n"
     ]
    }
   ],
   "source": [
    "\"ðŸ”’\"\n",
    "# @check\n",
    "# @title: check npz file size.\n",
    "\n",
    "size = round(os.lstat('./dataset.npz').st_size / (2 ** 20))\n",
    "print(f\"File size = {size} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14ba5ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.load('./dataset.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38258e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: 25000\n"
     ]
    }
   ],
   "source": [
    "print(\"Training dataset: %d\" % len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "195e6bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a train test split. the test set will have 20% of the data\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [int(len(dataset) * 0.8), int(len(dataset) * 0.2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "334112b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: 20000\n",
      "Test dataset: 5000\n"
     ]
    }
   ],
   "source": [
    "print(\"Training dataset: %d\" % len(train_dataset))\n",
    "print(\"Test dataset: %d\" % len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da3d0250",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_dataset, './train_dataset_extended.npz')\n",
    "torch.save(test_dataset, './test_dataset_extended.npz')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
